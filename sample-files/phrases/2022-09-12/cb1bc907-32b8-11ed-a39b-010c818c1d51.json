{"created_at": "2022-09-12 16:33:45.000000", "timestamp": "2022-09-12 16:34:38.130057", "user": "AmazonScience", "platform": "Twitter", "text_clean": "rt @parmidabeigi: amazon's 20b language model has fewer than 1/8 the number of parameters of gpt-3, yet outperforms it in several nlp tasks…", "count": 1, "phrase": "the number"}
{"created_at": "2022-09-12 16:33:45.000000", "timestamp": "2022-09-12 16:34:38.130057", "user": "AmazonScience", "platform": "Twitter", "text_clean": "rt @parmidabeigi: amazon's 20b language model has fewer than 1/8 the number of parameters of gpt-3, yet outperforms it in several nlp tasks…", "count": 1, "phrase": "amazon"}
{"created_at": "2022-09-12 16:33:45.000000", "timestamp": "2022-09-12 16:34:38.130057", "user": "AmazonScience", "platform": "Twitter", "text_clean": "rt @parmidabeigi: amazon's 20b language model has fewer than 1/8 the number of parameters of gpt-3, yet outperforms it in several nlp tasks…", "count": 1, "phrase": "20b language model"}
{"created_at": "2022-09-12 16:33:45.000000", "timestamp": "2022-09-12 16:34:38.130057", "user": "AmazonScience", "platform": "Twitter", "text_clean": "rt @parmidabeigi: amazon's 20b language model has fewer than 1/8 the number of parameters of gpt-3, yet outperforms it in several nlp tasks…", "count": 1, "phrase": "gpt-3"}
{"created_at": "2022-09-12 16:33:45.000000", "timestamp": "2022-09-12 16:34:38.130057", "user": "AmazonScience", "platform": "Twitter", "text_clean": "rt @parmidabeigi: amazon's 20b language model has fewer than 1/8 the number of parameters of gpt-3, yet outperforms it in several nlp tasks…", "count": 1, "phrase": "parameters"}
{"created_at": "2022-09-12 16:33:45.000000", "timestamp": "2022-09-12 16:34:38.130057", "user": "AmazonScience", "platform": "Twitter", "text_clean": "rt @parmidabeigi: amazon's 20b language model has fewer than 1/8 the number of parameters of gpt-3, yet outperforms it in several nlp tasks…", "count": 1, "phrase": "tasks…"}
{"created_at": "2022-09-12 16:33:45.000000", "timestamp": "2022-09-12 16:34:38.130057", "user": "AmazonScience", "platform": "Twitter", "text_clean": "rt @parmidabeigi: amazon's 20b language model has fewer than 1/8 the number of parameters of gpt-3, yet outperforms it in several nlp tasks…", "count": 1, "phrase": "fewer than 1/8"}
{"created_at": "2022-09-12 16:33:45.000000", "timestamp": "2022-09-12 16:34:38.130057", "user": "AmazonScience", "platform": "Twitter", "text_clean": "rt @parmidabeigi: amazon's 20b language model has fewer than 1/8 the number of parameters of gpt-3, yet outperforms it in several nlp tasks…", "count": 1, "phrase": "rt @parmidabeigi"}
